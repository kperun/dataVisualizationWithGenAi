{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waSS96gPuPCF"
   },
   "source": [
    "# **Welcome to The Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlZamiGhutkW"
   },
   "source": [
    "### Task 1 - Setting up the project environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3vynbDOu1F6"
   },
   "source": [
    "Installing the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "scn7mBZ6J_xW",
    "outputId": "73f75026-2a7e-4e56-db16-80bf3537036d"
   },
   "outputs": [],
   "source": [
    "!pip install openai==0.28 python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZfGLwZGu7Ub"
   },
   "source": [
    "Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hV3HIWIu-5b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import re\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJSWMOV3vCQ1"
   },
   "source": [
    "Setting up the OpenAI API:\n",
    "\n",
    "1. Prepare a `.env` file to store the OpenAI API key.\n",
    "2. Uploading the `.env` file to our colab environment\n",
    "3. Load the API key and setup the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xy4rUlZFJmLO"
   },
   "source": [
    "Upload your `.env` file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "3HKFQThwJlhI",
    "outputId": "3946da47-575e-4112-983d-2ee6f933b05c"
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3PJlXaIL_L-"
   },
   "source": [
    "Now let's load environment variables and get the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTA95zNovJ-h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLTngLSOMnCV"
   },
   "source": [
    "Let's setup our OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csXxHaNeMqbU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2sF80TRaQTlo"
   },
   "source": [
    "### Task 2 - Craft Prompts to Communicate with the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dMeTCJkWI6S"
   },
   "source": [
    "To communicate with the API we need to learn how to craft a prompt.\n",
    "\n",
    "A prompt object contains two elements:\n",
    "1. Role: Specifies the communicator's roleâ€”either `User`, `System`, or `Assistant`.\n",
    "2. Content: Contains the text of the communication\n",
    "\n",
    "example:\n",
    "`prompt = {'role': 'user', 'content': 'what is the captial of Italy?'}`\n",
    "\n",
    "Different Roles:\n",
    "\n",
    "- **User**: Initiates the conversation, asks questions, and gives instructions to - the AI model.\n",
    "- **System**: Sets the initial context or instructions for the conversation, guiding the AI's behavior.\n",
    "- **Assistant**: Generates responses based on the user's queries and the context provided by the system, acting as the AI model's replies.\n",
    "\n",
    "User initiates the conversation, system provides context, and assistant generates responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcqGQShpQWdo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHNLz8cmXQ8x"
   },
   "source": [
    "### Task 3 - Generate and Execute python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vw5pnEHd1JvF"
   },
   "source": [
    "Define a function to generate a chat response using the OpenAI GPT-4 model, given system and user messages as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk9s7Cn209Au"
   },
   "outputs": [],
   "source": [
    "def generate_chat_response(system_content, user_content):\n",
    "    # Create two message dictionaries, one for the system and one for the user.\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "\n",
    "    # Use OpenAI's ChatCompletion API to generate a response.\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[system, user],  # List of messages (system and user)\n",
    "        max_tokens=1200  # Set a limit on the number of tokens in the response\n",
    "    )\n",
    "\n",
    "    # Return the generated response.\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqynV95a0bg6"
   },
   "source": [
    "Let's craft a prompt to generate a simple python method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fF_6iPX0iuK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HE2Yzdv0zdOw"
   },
   "source": [
    "Let's extract the code from the prompt response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zb7kWqheUWeq"
   },
   "outputs": [],
   "source": [
    "def extract_code(response_content):\n",
    "    # Define a regular expression pattern to match text between triple backticks (```)\n",
    "    pattern = r'```(.*?)```'\n",
    "\n",
    "    # Use re.findall to find all non-overlapping matches of the pattern in the input string\n",
    "    matches = re.findall(pattern, response_content, re.DOTALL)\n",
    "\n",
    "    # Remove the python keyword from in the code and Return the first match found\n",
    "    return matches[0].replace(\"python\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unC1WW7y08xg"
   },
   "source": [
    "Now let's execute the generated code and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBjGxmjhgkW1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OysV-evMv5n7"
   },
   "source": [
    "### Task 4 - Generate Python Code for Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5s8siqoxfvL"
   },
   "source": [
    "Defining `generate_code` helper method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3t-fTivvw9He"
   },
   "outputs": [],
   "source": [
    "def generate_code(system_content, user_content):\n",
    "    # Create two message dictionaries, one for the system and one for the user.\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "\n",
    "    # Use OpenAI's ChatCompletion API to generate a response.\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[system, user],  # List of messages (system and user)\n",
    "        max_tokens=1200  # Set a limit on the number of tokens in the response\n",
    "    )\n",
    "\n",
    "    # Extract the response content\n",
    "    response_content = response.choices[0].message.content\n",
    "\n",
    "    # Define a regular expression pattern to match text between triple backticks (```)\n",
    "    pattern = r'```(.*?)```'\n",
    "\n",
    "    # Use re.findall to find all non-overlapping matches of the pattern in the input string\n",
    "    matches = re.findall(pattern, response_content, re.DOTALL)\n",
    "\n",
    "    # Remove the python keyword from in the code and Return the first match found\n",
    "    return matches[0].replace(\"python\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDxhsA_EyoJF"
   },
   "source": [
    "Let's load product sales dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "NiK75QPbyrgD",
    "outputId": "6e8d0047-bfef-4361-d94d-e39e50796ebe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDD0uSHXAiWo"
   },
   "source": [
    "Let's check the data types in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BGS_hepG-THO",
    "outputId": "51307757-9c91-4585-b8ae-0dc387b1b623"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDU7R4ndAmjj"
   },
   "source": [
    "**Some Data Preparation**\n",
    "* Extract month name from the `date` column\n",
    "* Calculate profit per product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZonfVoUAltP",
    "outputId": "90e5cb49-54eb-4136-ca4d-e3480611563f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MG2Ap0pNDOcK"
   },
   "source": [
    "Let's execute this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7q-JiKICDRIC",
    "outputId": "1a4cfa8a-3384-431e-b0da-ac0efc6b6a67"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rs6frRFlD6WH"
   },
   "source": [
    "Lets calculate profit per product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91f3QK2YDW_H",
    "outputId": "711bab8f-faa2-4730-be5e-d01b2f160ffd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVzzOwlTFT2A"
   },
   "source": [
    "Now let's execute this code and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "ZS6IyKo4E5E1",
    "outputId": "548e1efe-ebd2-4edf-9db3-4ca39aa0f3c3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z11i_5RpFsQp"
   },
   "source": [
    "### Task 5 - Generate Python Code for Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqlZldsFF8_k"
   },
   "source": [
    "Defining some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FikByEF6FymM"
   },
   "outputs": [],
   "source": [
    "def generate_chat_response(system_content, user_content):\n",
    "    # Create two message dictionaries, one for the system and one for the user.\n",
    "    system = {'role': 'system', 'content': system_content}\n",
    "    user = {'role': 'user', 'content': user_content}\n",
    "\n",
    "    # Use OpenAI's ChatCompletion API to generate a response.\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=[system, user],  # List of messages (system and user)\n",
    "        max_tokens=1200  # Set a limit on the number of tokens in the response\n",
    "    )\n",
    "\n",
    "    # Return the generated response.\n",
    "    return response\n",
    "\n",
    "\n",
    "def extract_code(response_content):\n",
    "    # Define a regular expression pattern to match text between triple backticks (```)\n",
    "    pattern = r'```(.*?)```'\n",
    "\n",
    "    # Use re.findall to find all non-overlapping matches of the pattern in the input string\n",
    "    matches = re.findall(pattern, response_content, re.DOTALL)\n",
    "\n",
    "    # Remove the python keyword from in the code and Return the first match found\n",
    "    return matches[0].replace(\"python\", \"\")\n",
    "\n",
    "\n",
    "def generate_code_and_execute(user_content, execute=True):\n",
    "    # Defining system content for code generation\n",
    "    system_content = \"\"\"\n",
    "    You are a python code generator. You know pandas. You answer to every question with Python code.\n",
    "    You return python code wrapped in ``` delimiter. Import any neede python module. And you don't provide any elaborations.\n",
    "    \"\"\"\n",
    "\n",
    "    # generate chat response\n",
    "    response = generate_chat_response(system_content, user_content)\n",
    "\n",
    "    # extract resonse content\n",
    "    response_content = response.choices[0].message.content\n",
    "\n",
    "    # let's extract the code from the response content\n",
    "    code = extract_code(response_content)\n",
    "\n",
    "    if execute:\n",
    "        exec(code, globals())  # Execute the generated Python code if execute is set to True\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "def update_code(code, user_content, execute = True):\n",
    "    # Defining system content for code update\n",
    "    system_content = f\"\"\"\n",
    "    You are a python code generator. You know pandas. You are given the following python method: {code}. Update the code based on the user content. Do not change the method name.\n",
    "    You return the updated python code wrapped in ``` delimiter. And you don't provide any elaborations.\n",
    "    \"\"\"\n",
    "    # generate chat response\n",
    "    response_content = generate_chat_response(system_content, user_content).choices[0].message.content\n",
    "\n",
    "    # extracting the code\n",
    "    new_code = extract_code(response_content)\n",
    "\n",
    "    if execute:\n",
    "        exec(new_code, globals())  # Execute the generated Python code if execute is set to True\n",
    "\n",
    "    return new_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTqZ35pjtnRx"
   },
   "source": [
    "Let's check our data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uyxBLUy8svbK",
    "outputId": "10e18303-b448-4586-a817-1b5deb7d0c6d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26FZODafwCey"
   },
   "source": [
    "\n",
    "**Question 1-** How does the daily `average` profit change over time?\n",
    "\n",
    "Steps to answer this question:\n",
    "\n",
    "1. Aggregate our data to have average `Product_Profit` per day.\n",
    "2. Draw a line chart to visualize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAHyXbfOvX3J",
    "outputId": "bb880ced-8df1-4355-9c50-638be4f0fd90"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zpe6jn3B8uhE"
   },
   "source": [
    "Let's use the generated method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "hY9QhMIV5yea",
    "outputId": "adf686e2-f32e-48fa-b73c-6f6145377b33"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAU20IviGGb4"
   },
   "source": [
    "What if we want to update the generated visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8ojRLz8zem5",
    "outputId": "014039c8-4e99-4f20-9c67-57f43cd894f7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucJEB92I_Ltz"
   },
   "source": [
    "Running the new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "uFnsmn285Vpe",
    "outputId": "3bb23e7d-f68e-43ca-a952-0b961e5edf9e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGk0ftFur9xs"
   },
   "source": [
    "**Execrise:** Question 2 - Create a barchart visualization to show total average profit per Product Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXK-mk2W5ftU",
    "outputId": "bc866470-7f8f-468d-faed-767a5ffe6546"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "id": "XaeApPxnuThL",
    "outputId": "0952a615-865a-45b7-9be0-c137397a5f4c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zfu-fTgIuZlF"
   },
   "source": [
    "Updating the code to have bar chart with different bar color per product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "id": "y36xxUknueeE",
    "outputId": "d3017039-f8eb-4ea3-a390-7e888dfd8444"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3smjNBfzJ8W"
   },
   "source": [
    "### Task 6 - Create Visualizations using AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7J5WHcDHbTB"
   },
   "source": [
    "Let's checkout the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TSnc88aP6mo3",
    "outputId": "b8ab2b64-c5b2-45d0-88c2-c88a9c3027ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r1Py-TszzP7"
   },
   "source": [
    "**Question 3** - Which product has the highest total sold items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "i3TSRVbGzusN",
    "outputId": "a24f15e7-99ae-46c0-d88e-92c4a04ce4de"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8UPA-5_7wXG"
   },
   "source": [
    "Let's make it a horizontal bar chart and highlight the prodcut with the highest number of sold items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "Uwy_OTDm7e6I",
    "outputId": "a6f38585-3fa9-4e39-c0ab-d711c71a1bd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZlZamiGhutkW",
    "2sF80TRaQTlo",
    "WHNLz8cmXQ8x",
    "OysV-evMv5n7",
    "BDU7R4ndAmjj",
    "z11i_5RpFsQp",
    "x3smjNBfzJ8W"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
